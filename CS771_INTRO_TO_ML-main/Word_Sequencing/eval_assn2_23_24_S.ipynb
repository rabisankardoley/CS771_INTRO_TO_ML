{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "Requirement already satisfied: packaging in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from keras) (21.3)Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting absl-py\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Collecting ml-dtypes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
            "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
            "jupyter-server 1.13.5 requires pywinpty<2; os_name == \"nt\", but you have pywinpty 2.0.2 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading ml_dtypes-0.4.0-cp39-cp39-win_amd64.whl (126 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from keras) (1.21.5)\n",
            "Collecting rich\n",
            "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "Requirement already satisfied: h5py in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from keras) (3.6.0)\n",
            "Collecting namex\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree\n",
            "  Downloading optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n",
            "Collecting typing-extensions>=4.5.0\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from packaging->keras) (3.0.4)\n",
            "Collecting pygments<3.0.0,>=2.13.0\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: mdurl, typing-extensions, pygments, markdown-it-py, rich, optree, namex, ml-dtypes, absl-py, keras\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.11.2\n",
            "    Uninstalling Pygments-2.11.2:\n",
            "      Successfully uninstalled Pygments-2.11.2\n",
            "Successfully installed absl-py-2.1.0 keras-3.4.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 optree-0.12.1 pygments-2.18.0 rich-13.7.1 typing-extensions-4.12.2\n"
          ]
        }
      ],
      "source": [
        "%pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optree in c:\\users\\digvi\\anaconda3\\lib\\site-packages (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\digvi\\anaconda3\\lib\\site-packages (from optree) (4.12.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install optree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: typing-extensions in c:\\users\\digvi\\anaconda3\\lib\\site-packages (4.12.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade typing-extensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/tensorflow/\n",
            "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000239E1030400>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/b4/71/1ac7960071a524fa25d7e9dd5040da26d3e15802d869c588d7e4cd8036f9/tensorflow-2.17.0-cp39-cp39-win_amd64.whl\n",
            "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000239E10305E0>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/b4/71/1ac7960071a524fa25d7e9dd5040da26d3e15802d869c588d7e4cd8036f9/tensorflow-2.17.0-cp39-cp39-win_amd64.whl\n",
            "  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000239E1030790>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/b4/71/1ac7960071a524fa25d7e9dd5040da26d3e15802d869c588d7e4cd8036f9/tensorflow-2.17.0-cp39-cp39-win_amd64.whl\n",
            "  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000239E0A8C2E0>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/b4/71/1ac7960071a524fa25d7e9dd5040da26d3e15802d869c588d7e4cd8036f9/tensorflow-2.17.0-cp39-cp39-win_amd64.whl\n",
            "  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000239E101EB80>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/b4/71/1ac7960071a524fa25d7e9dd5040da26d3e15802d869c588d7e4cd8036f9/tensorflow-2.17.0-cp39-cp39-win_amd64.whl\n",
            "ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Max retries exceeded with url: /packages/b4/71/1ac7960071a524fa25d7e9dd5040da26d3e15802d869c588d7e4cd8036f9/tensorflow-2.17.0-cp39-cp39-win_amd64.whl (Caused by NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000239E101EC40>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9UkDauX8Byb3"
      },
      "outputs": [],
      "source": [
        "\n",
        "from submit import my_fit, my_predict\n",
        "import time as tm\n",
        "import pickle\n",
        "import warnings\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open( \"dict\", 'r' ) as f:\n",
        "\twords_train = f.read().split( '\\n' )[:-1]\t\t# Omit the last line since it is empty\n",
        "\tnum_words = len( words_train )\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Wdq2X6uVB8rh"
      },
      "outputs": [],
      "source": [
        "with open( \"dummy/dict_secret\", 'r' ) as f:\n",
        "\twords_test = f.read().split( '\\n' )[:-1]\t\t# Omit the last line since it is empty\n",
        "\tnum_words = len( words_test )\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UQrLNsaGB-f_"
      },
      "outputs": [],
      "source": [
        "n_trials = 5\n",
        "\n",
        "t_train = 0\n",
        "m_size = 0\n",
        "t_test = 0\n",
        "prec = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MAsWDD5iChyt"
      },
      "outputs": [],
      "source": [
        "def get_bigrams( word, lim = None ):\n",
        "  # Get all bigrams\n",
        "  bg = map( ''.join, list( zip( word, word[1:] ) ) )\n",
        "  # Remove duplicates and sort them\n",
        "  bg = sorted( set( bg ) )\n",
        "  # Make them into an immutable tuple and retain only the first few\n",
        "  return tuple( bg )[:lim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fC5OSDt9CF1p"
      },
      "outputs": [],
      "source": [
        "lim_bg = 5\n",
        "lim_out = 5\n",
        "\n",
        "for t in range(n_trials):\n",
        "    tic = tm.perf_counter()\n",
        "    model = my_fit(words_train)\n",
        "    toc = tm.perf_counter()\n",
        "    t_train += toc - tic\n",
        "\n",
        "    with open(f\"model_dump_{t}.pkl\", \"wb\") as outfile:\n",
        "        pickle.dump(model, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    m_size += os.path.getsize(f\"model_dump_{t}.pkl\")\n",
        "\n",
        "    tic = tm.perf_counter()\n",
        "\n",
        "    for (i, word) in enumerate(words_test):\n",
        "        bg = get_bigrams(word, lim=lim_bg)\n",
        "        guess_list = my_predict(model, bg)\n",
        "\n",
        "        # Do not send long guess lists -- they will result in lower marks\n",
        "        guess_len = len(guess_list)\n",
        "        # Ignore all but the first 5 guesses\n",
        "        guess_list = guess_list[:lim_out]\n",
        "\n",
        "        # Notice that if 10 guesses are made, one of which is correct,\n",
        "        # score goes up by 1/10 even though only first 5 guesses are considered\n",
        "        # Thus, it is never beneficial to send more than 5 guesses\n",
        "        if word in guess_list:\n",
        "            prec += 1 / guess_len\n",
        "\n",
        "    toc = tm.perf_counter()\n",
        "    t_test += toc - tic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmub4R58CJ1E",
        "outputId": "23908a38-2be9-40e3-c481-c6c0966d2601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.337200700000016 417337732.0 0.9750338687826592 0.9234471000000439\n"
          ]
        }
      ],
      "source": [
        "t_train /= n_trials\n",
        "m_size /= n_trials\n",
        "t_test /= n_trials\n",
        "prec /= ( n_trials * num_words )\n",
        "\n",
        "print( t_train, m_size, prec, t_test  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkwRLJs5bgwt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
